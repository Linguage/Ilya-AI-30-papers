# 1611.02731v2.Variational_Lossy_Autoencoder.pdf

## 基本信息
- **标题**: Variational Lossy Autoencoder
- **作者**: Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, Pieter Abbeel
- **机构**: UC Berkeley, OpenAI
- **会议**: ICLR 2017
- **arXiv版本**: v2 (2017年3月4日)
- **页数**: 17页

## 摘要

表示学习寻求在学习的表示中暴露观测数据的某些方面，使其适合于分类等下游任务。例如，2D图像的良好表示可能是只描述全局结构并丢弃关于详细纹理信息的表示。在本文中，我们提出了一种简单但原则性的方法，通过将变分自编码器（VAE）与神经自回归模型（如RNN、MADE和PixelRNN/CNN）相结合来学习这种全局表示。我们提出的VAE模型允许我们控制全局潜在代码可以学习的内容，通过相应地设计架构，我们可以强制全局潜在代码丢弃无关信息，如2D图像中的纹理，因此VAE只以有损的方式"自编码"数据。此外，通过利用自回归模型作为先验分布p(z)和解码分布p(x|z)，我们可以大大提高VAE的生成建模性能，在MNIST、OMNIGLOT和Caltech-101轮廓密度估计任务上实现新的最先进结果，并在CIFAR10上获得竞争性结果。

## 引言

### 表示学习的目标
- **因果因素识别**: 表示学习的关键目标是识别和分离数据的潜在因果因素
- **全局结构**: 对于图像数据，这通常意味着我们感兴趣的是捕捉图像内容的"全局结构"
- **风格与内容**: 包括图像中存在对象的身份及其"风格"，但通常对局部和高频变化源（如特定纹理或白噪声模式）不太感兴趣

### 生成建模的挑战
- **不适定性**: 通过生成建模进行表示学习是不适定的
- **架构依赖**: 使用这种方法获得的实证结果高度依赖于特定的架构和建模选择
- **目标脱节**: 我们优化的目标通常与学习好的表示的目标完全脱节

### 自回归模型的局限
- **生成能力强**: 自回归模型作为生成模型非常强大
- **表示学习弱**: 但由于没有随机潜在变量，在表示学习目的方面不太受欢迎
- **结构差异**: 自回归模型学习的结构与VAE完全不同

### 混合模型的潜力
- **最佳结合**: 结合VAE的潜在变量结构和自回归模型的强大循环性
- **历史问题**: 之前结合这两种模型的尝试遇到了问题，自回归部分最终解释了数据中的所有结构
- **解决方案**: 通过弱化模型的自回归部分来鼓励使用潜在变量

## VAE不自编码的一般情况

### VAE的误解
- **常见解释**: VAE经常被解释为正则化自编码器
- **保证条件**: 但保证自编码（重建接近原始数据点）的条件没有被讨论
- **潜在代码使用**: 之前在序列建模中应用VAE的尝试发现潜在代码通常不被使用

### 技术背景
- **变量定义**: x是观测变量，z是潜在变量，p(x,z)是它们联合分布的参数模型
- **生成模型**: 称为在变量上定义的生成模型
- **最大似然学习**: 给定数据集X = {x1, ..., xN}，我们希望执行其参数的最大似然学习

## VLAE的创新

### 原则性解决方案
- **信息控制**: 利用弱化属性来控制什么类型的信息进入潜在变量
- **密度估计**: 作为密度估计器表现良好
- **表示学习**: 具有独特适合学习数据有趣全局表示的结构

### 模型特点
- **有损自编码**: VAE只以有损的方式"自编码"数据
- **全局表示**: 强制全局潜在代码丢弃无关信息
- **架构设计**: 通过设计架构控制潜在代码学习的内容

## 实验结果

### 密度估计性能
- **MNIST**: 实现新的最先进对数似然结果
- **OMNIGLOT**: 在密度估计任务上取得最先进结果
- **Caltech-101**: 在轮廓密度估计任务上表现优异
- **CIFAR10**: 获得竞争性结果

### 表示学习效果
- **全局结构**: 成功学习数据的全局结构
- **信息丢弃**: 能够丢弃无关信息如纹理
- **层次结构**: 保持清晰的潜在变量层次结构

## 技术贡献

### 理论分析
1. **VAE行为**: 深入分析了VAE不自编码的一般情况
2. **弱化必要性**: 解释了为什么弱化自回归部分是必要的
3. **信息控制**: 提出了控制潜在变量信息类型的原则性方法

### 实践创新
1. **混合架构**: 成功结合VAE和自回归模型的优势
2. **性能提升**: 在多个基准测试上实现最先进结果
3. **表示质量**: 学习到有意义和有用的全局表示

## 意义与影响

1. **理论突破**: 解决了VAE不自编码的理论问题
2. **方法创新**: 提出了原则性的表示学习方法
3. **性能提升**: 在生成建模和表示学习两方面都取得突破
4. **应用前景**: 为下游任务提供了更好的表示学习方法

这篇论文为变分自编码器和表示学习提供了重要的理论见解和实践方法，成功结合了生成建模和表示学习的优势。